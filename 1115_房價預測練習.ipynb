{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "1115 房價預測練習",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biolytic1996/python-learning1996/blob/master/1115_%E6%88%BF%E5%83%B9%E9%A0%90%E6%B8%AC%E7%B7%B4%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHKdD1qU62DF"
      },
      "source": [
        "# 實驗一：房價預測模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnhWEyv-62DH"
      },
      "source": [
        "### Import必要套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abDmAO862DI"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRPHVV-D-FwS"
      },
      "source": [
        "## Step 1. 設定 Google Drive 連接 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjFZLoyA-I5K",
        "outputId": "0448f099-b2f0-4756-f96d-b2116005905c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # 點擊網址，選擇 Google 帳號登入，然後將授權碼貼回輸入框中"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja5FAB-HDGDb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFx5kPLa-YCL"
      },
      "source": [
        "!ln -fs /content/gdrive/My\\ Drive/ /app  #執行一次就可，否則會有錯誤訊息"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Rk_LcJDHNf",
        "outputId": "c8ef5e5f-da84-4ce9-d819-70da2e6bfaab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /app"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keDyMyFSb-r8"
      },
      "source": [
        "### https://www.kaggle.com/shivachandel/kc-house-data\n",
        "### http://www.stodolkiewicz.com/2020/01/28/tensorflow-2-regression-on-the-boston-housing-dataset-part-2-keras-callbacks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ujBpka1cE8"
      },
      "source": [
        "### 步驟 2. 下載 cuDNN 檔案\n",
        "\n",
        "1. 申請 Nvidia 帳號，申請網址為 http://bit.ly/2qfpOPj\n",
        "2. 下載 `cudnn-10.0-linux-x64-v7.5.0.56.tgz`，下載網址為 \n",
        "下載 cuDNN 檔案。下載網址為：http://bit.ly/2qfpOPj\n",
        "3. 將下載的檔案 `cudnn-10.0-linux-x64-v7.5.0.56.tgz` 放到 google drive 的 `Colab Notebooks/cuDNN/` 目錄下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1uWe9rV1i1p",
        "outputId": "090efdc7-539e-47e5-ca0f-20939a358198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tar -xzvf /app/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "\n",
        "# 檢查是否安裝成功\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda/include/cudnn.h\n",
            "cuda/NVIDIA_SLA_cuDNN_Support.txt\n",
            "cuda/lib64/libcudnn.so\n",
            "cuda/lib64/libcudnn.so.7\n",
            "cuda/lib64/libcudnn.so.7.5.0\n",
            "cuda/lib64/libcudnn_static.a\n",
            "#define CUDNN_MAJOR 7\n",
            "#define CUDNN_MINOR 5\n",
            "#define CUDNN_PATCHLEVEL 0\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "#include \"driver_types.h\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0i2MFvo62DN"
      },
      "source": [
        "### 數據讀取並分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OCiPHM2K62DN",
        "outputId": "b7c97e79-d50d-4d70-b441-8bc032c0f903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = pd.read_csv(\"/app/kc_house_data.csv\")\n",
        "# 顯示dataset的形狀，共21613比資料，每一比資料有21種不同資訊。\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21613, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3on7lew62DS",
        "outputId": "659d7dc5-f18d-4972-f320-30576be15eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# 將顯示列數設定為25，不然會有部份資料無法顯示\n",
        "pd.options.display.max_columns = 25\n",
        "# head 會顯示前五行的數據\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
              "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
              "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
              "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
              "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
              "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
              "\n",
              "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
              "0      5650     1.0           0     0          3      7      1180.0   \n",
              "1      7242     2.0           0     0          3      7      2170.0   \n",
              "2     10000     1.0           0     0          3      6       770.0   \n",
              "3      5000     1.0           0     0          5      7      1050.0   \n",
              "4      8080     1.0           0     0          3      8      1680.0   \n",
              "\n",
              "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
              "0              0      1955             0    98178  47.5112 -122.257   \n",
              "1            400      1951          1991    98125  47.7210 -122.319   \n",
              "2              0      1933             0    98028  47.7379 -122.233   \n",
              "3            910      1965             0    98136  47.5208 -122.393   \n",
              "4              0      1987             0    98074  47.6168 -122.045   \n",
              "\n",
              "   sqft_living15  sqft_lot15  \n",
              "0           1340        5650  \n",
              "1           1690        7639  \n",
              "2           2720        8062  \n",
              "3           1360        5000  \n",
              "4           1800        7503  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZULEp-y62DW"
      },
      "source": [
        "各個數據的簡寫分別代表下面意思：\n",
        "- date：房屋出售日期。\n",
        "- price：房屋價格（目標）。\n",
        "- bedrooms：臥室數量。\n",
        "- bathrooms：浴室數量。\n",
        "- sqft_living：居住的坪數（平方英尺）。\n",
        "- sqft_lot：實際的坪數（平方英尺）。\n",
        "- floors：房屋總共樓層。\n",
        "- waterfront：海景房。\n",
        "- view：房屋是否看過。\n",
        "- condition：整體條件有多好。\n",
        "- grade：房屋的整體等級（根據King County評分系統）。\n",
        "- sqft_above：除了地下室外的坪數（平方英尺）。\n",
        "- sqft_basement：地下室的坪數（平方英尺）。\n",
        "- yr_built：房屋建造時間。\n",
        "- yr_renovated：何時重新裝修過（一些沒重新裝修過或是裝修紀錄沒被記錄到的數值都為0）。\n",
        "- zipcode：郵政編碼。\n",
        "- lat：緯度座標。\n",
        "- long：經度座標。\n",
        "- sqft_living15：2015年紀錄的居住坪數（可能是翻新的原因導致sqft_living15與sqft_living不同）。\n",
        "- sqft_lot15：2015年紀錄的實際坪數（可能是翻新的原因導致sqft_lot15與sqft_lot不同）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVWFc68N62DX"
      },
      "source": [
        "### 檢查資料的型態\n",
        "\n",
        "資料型態總共有五種：object(string),booleab, integer, float and categorical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21xrCehU62DY",
        "outputId": "47114d10-9fb7-4085-900a-10507f66edc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "price            float64\n",
              "bedrooms           int64\n",
              "bathrooms        float64\n",
              "sqft_living        int64\n",
              "sqft_lot           int64\n",
              "floors           float64\n",
              "waterfront         int64\n",
              "view               int64\n",
              "condition          int64\n",
              "grade              int64\n",
              "sqft_above       float64\n",
              "sqft_basement      int64\n",
              "yr_built           int64\n",
              "yr_renovated       int64\n",
              "zipcode            int64\n",
              "lat              float64\n",
              "long             float64\n",
              "sqft_living15      int64\n",
              "sqft_lot15         int64\n",
              "year               int64\n",
              "month              int64\n",
              "day                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIDSVGMoEBZh"
      },
      "source": [
        "date20141013T000000是物件  要處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90wPmfor62Dc"
      },
      "source": [
        "### 數據前處理\n",
        "轉換資料型態：\n",
        "因為數據集裡的date數據是字串（string）格式，而模型的輸入只接受數值格式，所以可以透過以下程式碼將其轉為數值，並分成年、月及日三種數據。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-KeJgIW62De",
        "outputId": "0ed50586-369c-45fb-e4ba-17299fa0a23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "# 將date日期拆為年、月和日並轉成數值\n",
        "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))#新增year欄位儲存 將原本的資料轉文字再切片擷取\n",
        "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
        "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
        "\n",
        "# 刪除沒有用的數據，inplace則是將更新後的資料存回原本的地方\n",
        "data.drop(['id'], axis=\"columns\", inplace=True)\n",
        "data.drop(['date'], axis=\"columns\", inplace=True)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3218cb96fd41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 將date日期拆為年、月和日並轉成數值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#新增year欄位儲存 將原本的資料轉文字再切片擷取\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ILOQaNA62Dj"
      },
      "source": [
        "分割數據集（Dataset）：將數據集切割成三個部份，訓練數據（Training data）、驗證數據（Validation data）和測試數據（Testing data）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij63xCTu62Dj"
      },
      "source": [
        "data_num = data.shape[0]#21613筆\n",
        "# 取得一筆與data數量相同的亂數索引，主要目的是用於打散資料\n",
        "indexes = np.random.permutation(data_num)\n",
        "# 並將亂數索引值分為Train、validation和test分為，這裡的劃分比例為6:2:2\n",
        "train_indexes = indexes[:int(data_num *0.6)]\n",
        "val_indexes = indexes[int(data_num *0.6):int(data_num *0.8)]\n",
        "test_indexes = indexes[int(data_num *0.8):]\n",
        "# 透過索引值從data取出訓練資料、驗證資料和測試資料\n",
        "train_data = data.loc[train_indexes]\n",
        "val_data = data.loc[val_indexes]\n",
        "test_data = data.loc[test_indexes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OojnFm5-62Dn"
      },
      "source": [
        "### Normalization 正規化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RurfzID162Do"
      },
      "source": [
        "使用標準分數(Standard Score, 又稱z-score)將數據正規化，經過z-score正規化後數據的都會聚集在0附近， 標準差為1。 \n",
        "\n",
        "(x - 平均值) / 標準差"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qDtQMNKJ62Do"
      },
      "source": [
        "train_validation_data = pd.concat([train_data, val_data])\n",
        "mean = train_validation_data.mean()\n",
        "std = train_validation_data.std()\n",
        "\n",
        "train_data = (train_data - mean) / std\n",
        "val_data = (val_data - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mh9rTpB62Ds"
      },
      "source": [
        "### 建立Numpy array格式的訓練數據"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN5_H4Bh62Ds"
      },
      "source": [
        "x_train = np.array(train_data.drop('price', axis='columns'))\n",
        "y_train = np.array(train_data['price'])# 把價格拉出來\n",
        "x_val = np.array(val_data.drop('price', axis='columns'))\n",
        "y_val = np.array(val_data['price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9z_JEa-62Dw"
      },
      "source": [
        "整理過後的資料共12967筆，且一筆資料有21種資訊(所以網路輸入必須為21)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWm5RX8262Dw",
        "outputId": "73c236da-b94d-4383-b3c8-680ec0b6e80d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12967, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb8474xRIkW6"
      },
      "source": [
        "每一筆有21個特徵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQjGDPClGy3J",
        "outputId": "4bdd66dc-c824-49eb-da54-cd0009a90291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.66532756, -1.44785658, -0.11023483, -0.19554945, -0.91512052,\n",
              "        -0.08770838, -0.30813775, -0.62878673, -0.55904124, -0.63558027,\n",
              "         0.95465518,  0.06556786, -0.21218674, -0.8172886 ,  1.15786226,\n",
              "         0.23602654, -0.60776582, -0.1848638 , -0.69540118,  1.74114685,\n",
              "         1.20013586],\n",
              "       [ 2.79876848,  0.16941609,  0.62351278, -0.03542096,  0.93286287,\n",
              "        -0.08770838, -0.30813775, -0.62878673, -0.55904124,  1.04962651,\n",
              "        -0.65938494, -1.16001954,  4.69777512,  0.88352498,  1.11316244,\n",
              "        -0.51553459, -1.2623335 , -0.16293246,  1.43793566, -1.77856659,\n",
              "        -1.58687608],\n",
              "       [-0.4013929 , -0.80094751, -0.86556325, -0.24311961,  0.93286287,\n",
              "        -0.08770838, -0.30813775,  0.90785251, -1.40744141, -0.61150589,\n",
              "        -0.65938494,  0.40600881, -0.21218674, -1.4153769 , -1.62578264,\n",
              "        -0.02631083, -1.33506324, -0.29647867, -0.69540118,  1.10119895,\n",
              "         0.15500638],\n",
              "       [ 0.66532756, -0.15403844,  1.05512902, -0.17152042,  0.93286287,\n",
              "        -0.08770838, -0.30813775,  0.90785251,  0.28935892,  0.30332065,\n",
              "         1.6271719 , -1.67068095, -0.21218674,  1.2386399 ,  0.14202293,\n",
              "        -0.54389538,  1.0795642 , -0.24987457,  1.43793566, -1.45859264,\n",
              "         0.38725738],\n",
              "       [-0.4013929 , -1.44785658, -0.93030568, -0.24958427, -0.91512052,\n",
              "        -0.08770838, -0.30813775, -0.62878673, -1.40744141, -0.68372904,\n",
              "        -0.65938494, -2.38560694, -0.21218674,  0.8274542 ,  0.36263814,\n",
              "        -0.66442877, -1.14596591, -0.2854774 , -0.69540118, -0.49867079,\n",
              "         1.66463785]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZD7vqBv62D0"
      },
      "source": [
        "### 建立並訓練網路模型\n",
        "\n",
        "這裡建構三層全連接層的網路架構，並且使用ReLU作為隱藏層的激活函數，而由於需得到線性輸出，故輸出層不使用任何激活函數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syzeGcExh10L",
        "outputId": "6290e657-2715-4f75-d120-4ddc3443cb9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 建立一個Sequential型態的model\n",
        "model = keras.Sequential(name='model-1')\n",
        "# 第1層全連接層設為64個unit，將輸入形狀設定為(21, )，而實際上我們輸入的數據形狀為(batch_size, 21)\n",
        "model.add(layers.Dense(21, activation='relu', input_shape=(21,)))#dense 全連接層的意思\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# 最後一層全連接層設為1個unit\n",
        "model.add(layers.Dense(1))\n",
        "# 顯示網路模型架構\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model-1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 21)                462       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                1408      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 6,095\n",
            "Trainable params: 6,095\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq3nQiFJIb_Q"
      },
      "source": [
        "21*21+21=462,1408=64*64+64 param 是參數總和\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9ZhzEg62D5"
      },
      "source": [
        "設定訓練使用的優化器、損失函數和指標函數："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfrX2uEC62D5"
      },
      "source": [
        "model.compile(keras.optimizers.Adam(0.001),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-585oEUi62D9"
      },
      "source": [
        "創建模型儲存目錄："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gxWwiYU62D9",
        "outputId": "efda31e3-f425-4f85-8454-a6c31634581e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_dir = '/app/lab2-logs/models/'\n",
        "%cd /app\n",
        "!rm -rf lab2-logs\n",
        "os.makedirs(model_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw7U2Cc262EA"
      },
      "source": [
        "設定回調函數："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk7CcQ1y62EE"
      },
      "source": [
        "訓練網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t7XYNN6dCQQ",
        "outputId": "b5e27e37-ddb9-4c00-f8e6-a43fe0aaee68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# TensorBoard回調函數會幫忙紀錄訓練資訊，並存成TensorBoard的紀錄檔\n",
        "log_dir = os.path.join('/app/lab2-logs', 'model-1')\n",
        "# patience: number of epochs that produced the monitored quantity with no improvement after which training will be stopped.\n",
        "# Simply speaking - If there is no improvement in mse on the test set after any 15 epochs -> stop the training procedure\n",
        "monitor_val_acc = EarlyStopping(monitor = 'val_loss', patience=15)#acc是正確率 loss值15次如果都沒有變就停下來\n",
        "\n",
        "# save the best model ( = lowest mse) to a file 'best_model.hdf5'\n",
        "modelCheckpoint = ModelCheckpoint(model_dir + '/Best-model-1.h5', save_best_only = True)\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "# pass the above callbacks to callbacks parameter\n",
        "history = model.fit(x_train, y_train, \n",
        "                batch_size=64,  # 批次大小設為64\n",
        "                epochs=300,  # 整個dataset訓練300遍\n",
        "                validation_data=(x_val, y_val), \n",
        "                callbacks=[monitor_val_acc, modelCheckpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3969 - mean_absolute_error: 0.3857 - val_loss: 0.2238 - val_mean_absolute_error: 0.2969\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.2196 - mean_absolute_error: 0.2929 - val_loss: 0.1902 - val_mean_absolute_error: 0.2765\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1875 - mean_absolute_error: 0.2731 - val_loss: 0.1757 - val_mean_absolute_error: 0.2624\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1676 - mean_absolute_error: 0.2560 - val_loss: 0.1597 - val_mean_absolute_error: 0.2494\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1541 - mean_absolute_error: 0.2463 - val_loss: 0.1480 - val_mean_absolute_error: 0.2421\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1422 - mean_absolute_error: 0.2375 - val_loss: 0.1515 - val_mean_absolute_error: 0.2389\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1340 - mean_absolute_error: 0.2307 - val_loss: 0.1504 - val_mean_absolute_error: 0.2362\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1296 - mean_absolute_error: 0.2258 - val_loss: 0.1355 - val_mean_absolute_error: 0.2239\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1216 - mean_absolute_error: 0.2208 - val_loss: 0.1328 - val_mean_absolute_error: 0.2205\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1202 - mean_absolute_error: 0.2191 - val_loss: 0.1319 - val_mean_absolute_error: 0.2294\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1139 - mean_absolute_error: 0.2127 - val_loss: 0.1267 - val_mean_absolute_error: 0.2193\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1109 - mean_absolute_error: 0.2108 - val_loss: 0.1257 - val_mean_absolute_error: 0.2167\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1091 - mean_absolute_error: 0.2069 - val_loss: 0.1244 - val_mean_absolute_error: 0.2159\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1066 - mean_absolute_error: 0.2059 - val_loss: 0.1220 - val_mean_absolute_error: 0.2155\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1054 - mean_absolute_error: 0.2034 - val_loss: 0.1218 - val_mean_absolute_error: 0.2107\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.1017 - mean_absolute_error: 0.2021 - val_loss: 0.1207 - val_mean_absolute_error: 0.2097\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0968 - mean_absolute_error: 0.1971 - val_loss: 0.1293 - val_mean_absolute_error: 0.2126\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0988 - mean_absolute_error: 0.1983 - val_loss: 0.1208 - val_mean_absolute_error: 0.2113\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0965 - mean_absolute_error: 0.1964 - val_loss: 0.1298 - val_mean_absolute_error: 0.2194\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0941 - mean_absolute_error: 0.1943 - val_loss: 0.1215 - val_mean_absolute_error: 0.2111\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0925 - mean_absolute_error: 0.1950 - val_loss: 0.1135 - val_mean_absolute_error: 0.2030\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0904 - mean_absolute_error: 0.1906 - val_loss: 0.1189 - val_mean_absolute_error: 0.2045\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0853 - mean_absolute_error: 0.1877 - val_loss: 0.1172 - val_mean_absolute_error: 0.2046\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0867 - mean_absolute_error: 0.1884 - val_loss: 0.1170 - val_mean_absolute_error: 0.2043\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0878 - mean_absolute_error: 0.1902 - val_loss: 0.1230 - val_mean_absolute_error: 0.2083\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0860 - mean_absolute_error: 0.1869 - val_loss: 0.1268 - val_mean_absolute_error: 0.2107\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0832 - mean_absolute_error: 0.1856 - val_loss: 0.1188 - val_mean_absolute_error: 0.2058\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0821 - mean_absolute_error: 0.1849 - val_loss: 0.1146 - val_mean_absolute_error: 0.2010\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0820 - mean_absolute_error: 0.1835 - val_loss: 0.1204 - val_mean_absolute_error: 0.2178\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0776 - mean_absolute_error: 0.1808 - val_loss: 0.1164 - val_mean_absolute_error: 0.2025\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0777 - mean_absolute_error: 0.1814 - val_loss: 0.1159 - val_mean_absolute_error: 0.2009\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0739 - mean_absolute_error: 0.1778 - val_loss: 0.1154 - val_mean_absolute_error: 0.2010\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0722 - mean_absolute_error: 0.1758 - val_loss: 0.1221 - val_mean_absolute_error: 0.2080\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0737 - mean_absolute_error: 0.1774 - val_loss: 0.1220 - val_mean_absolute_error: 0.2035\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0735 - mean_absolute_error: 0.1791 - val_loss: 0.1126 - val_mean_absolute_error: 0.2018\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0719 - mean_absolute_error: 0.1757 - val_loss: 0.1171 - val_mean_absolute_error: 0.2020\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0694 - mean_absolute_error: 0.1740 - val_loss: 0.1162 - val_mean_absolute_error: 0.2044\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0687 - mean_absolute_error: 0.1745 - val_loss: 0.1272 - val_mean_absolute_error: 0.2031\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0691 - mean_absolute_error: 0.1751 - val_loss: 0.1162 - val_mean_absolute_error: 0.2043\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0693 - mean_absolute_error: 0.1742 - val_loss: 0.1180 - val_mean_absolute_error: 0.2070\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0691 - mean_absolute_error: 0.1732 - val_loss: 0.1229 - val_mean_absolute_error: 0.2118\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0711 - mean_absolute_error: 0.1771 - val_loss: 0.1146 - val_mean_absolute_error: 0.2020\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0683 - mean_absolute_error: 0.1736 - val_loss: 0.1142 - val_mean_absolute_error: 0.2009\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0662 - mean_absolute_error: 0.1716 - val_loss: 0.1210 - val_mean_absolute_error: 0.2028\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0632 - mean_absolute_error: 0.1690 - val_loss: 0.1152 - val_mean_absolute_error: 0.2005\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0662 - mean_absolute_error: 0.1723 - val_loss: 0.1137 - val_mean_absolute_error: 0.2004\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.0639 - mean_absolute_error: 0.1677 - val_loss: 0.1111 - val_mean_absolute_error: 0.2020\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0610 - mean_absolute_error: 0.1672 - val_loss: 0.1112 - val_mean_absolute_error: 0.2016\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0604 - mean_absolute_error: 0.1657 - val_loss: 0.1171 - val_mean_absolute_error: 0.2003\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0601 - mean_absolute_error: 0.1655 - val_loss: 0.1127 - val_mean_absolute_error: 0.1999\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0625 - mean_absolute_error: 0.1681 - val_loss: 0.1134 - val_mean_absolute_error: 0.2019\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0622 - mean_absolute_error: 0.1681 - val_loss: 0.1152 - val_mean_absolute_error: 0.2081\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0598 - mean_absolute_error: 0.1658 - val_loss: 0.1180 - val_mean_absolute_error: 0.2027\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0623 - mean_absolute_error: 0.1664 - val_loss: 0.1228 - val_mean_absolute_error: 0.2202\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0643 - mean_absolute_error: 0.1687 - val_loss: 0.1118 - val_mean_absolute_error: 0.2001\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0556 - mean_absolute_error: 0.1608 - val_loss: 0.1135 - val_mean_absolute_error: 0.2081\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0559 - mean_absolute_error: 0.1609 - val_loss: 0.1227 - val_mean_absolute_error: 0.2100\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0637 - mean_absolute_error: 0.1697 - val_loss: 0.1317 - val_mean_absolute_error: 0.2152\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0551 - mean_absolute_error: 0.1615 - val_loss: 0.1134 - val_mean_absolute_error: 0.2040\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0536 - mean_absolute_error: 0.1609 - val_loss: 0.1127 - val_mean_absolute_error: 0.2004\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0541 - mean_absolute_error: 0.1620 - val_loss: 0.1164 - val_mean_absolute_error: 0.2016\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.0538 - mean_absolute_error: 0.1602 - val_loss: 0.1155 - val_mean_absolute_error: 0.2070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ_FMopPggbr"
      },
      "source": [
        "### 原課本程式 (執行階段發生錯誤)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU7m_eSA62EI"
      },
      "source": [
        "### 訓練結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5GsNEQw62EJ",
        "outputId": "337914b8-55f7-4937-ee9b-e83831044271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history.history.keys()  # 查看history儲存的資訊有哪些"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SVyhmqk62EN",
        "outputId": "45ed320b-f05c-486f-c174-fb81a3474a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.ylim(0.02, 0.2)\n",
        "plt.title('Mean square error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxAKwT0X62EQ",
        "outputId": "8e468183-75d4-4317-a7df-374f87044483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['mean_absolute_error'], label='train')\n",
        "plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
        "plt.ylim(0.12, 0.26)\n",
        "plt.title('Mean absolute error')\n",
        "plt.ylabel('metrics')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwq6o12e62ET"
      },
      "source": [
        "測試數據的誤差百分比：用測試數據預測房屋價格並與答案計算誤差百分比。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pXrckh262EU",
        "outputId": "8debf242-3472-4e24-e22b-96dfaf927ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 載入模型\n",
        "model = keras.models.load_model('/app/lab2-logs/models/Best-model-1.h5')\n",
        "# 先將房屋價格取出\n",
        "y_test = np.array(test_data['price'])\n",
        "# 標準化數據\n",
        "test_data = (test_data - mean) / std\n",
        "# 將輸入數據存成Numpy 格式\n",
        "x_test = np.array(test_data.drop('price', axis='columns'))\n",
        "# 預測測試數據\n",
        "y_pred = model.predict(x_test)\n",
        "# 將預測結果轉換回來(因為訓練時的訓練目標也有經過標準化)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "# 計算平均的誤差百分比\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "# 顯示誤差百分比\n",
        "print(\"Model_1 Percentage Error: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_1 Percentage Error: 43.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDdS4gu262EW"
      },
      "source": [
        "### TensorBoard 可視化工具"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id9FClNy62EX"
      },
      "source": [
        "# 這行指令可以幫助我們直接在jupyter notebook上顯示TensorBoard\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a6jznxns62Ec"
      },
      "source": [
        "%tensorboard --port 9530 --logdir /app/lab2-logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_xlBTzE62Ef"
      },
      "source": [
        "# 實驗二：過擬合問題\n",
        "\n",
        "### 方法一、減少網路權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "exnLSm5662Ef",
        "outputId": "4a1fcc9f-9a0e-43ab-c728-7566209f65f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = keras.Sequential(name='model-2')\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(21,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "\n",
        "model_2.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-2')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-2.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_2.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 27s - loss: 2.4924 - mean_absolute_error: 0.8881WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.2651s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.9318 - mean_absolute_error: 0.6234 - val_loss: 1.1104 - val_mean_absolute_error: 0.6527\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6351 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6384 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1102 - val_mean_absolute_error: 0.6531\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1094 - val_mean_absolute_error: 0.6574\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6386 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6348 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6383 - val_loss: 1.1096 - val_mean_absolute_error: 0.6559\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6381 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6348 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1103 - val_mean_absolute_error: 0.6531\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1102 - val_mean_absolute_error: 0.6532\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6352 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1094 - val_mean_absolute_error: 0.6574\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6386 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1103 - val_mean_absolute_error: 0.6528\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6355 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6381 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6553\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6384 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6386 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6382 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6351 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6352 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6559\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6385 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6387 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1103 - val_mean_absolute_error: 0.6531\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6381 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc2a1bbac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9bGkqub62Ej"
      },
      "source": [
        "### 加入L1或L2 正則化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "11OLybIw62Ej",
        "outputId": "c4cf6b2a-8b81-4d7f-aa81-e1a2be82a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3 = keras.Sequential(name='model-3')\n",
        "model_3.add(layers.Dense(64, \n",
        "                         kernel_regularizer=keras.regularizers.l2(0.001), \n",
        "                         activation='relu', input_shape=(21,)))\n",
        "model_3.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model_3.add(layers.Dense(1))\n",
        "\n",
        "model_3.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-3')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-3.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_3.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 10s - loss: 1.1976 - mean_absolute_error: 0.7815WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0975s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6248 - val_loss: nan - val_mean_absolute_error: 0.6572\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6592\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6523\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6511\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6516\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6588\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6603\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6395 - val_loss: nan - val_mean_absolute_error: 0.6509\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6346 - val_loss: nan - val_mean_absolute_error: 0.6579\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6566\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6358 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6575\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6382 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6358 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6574\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6387 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6382 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6351 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6571\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6352 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6351 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6566\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6383 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6532\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6531\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6531\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6532\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6533\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6386 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6353 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6383 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6352 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6567\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6391 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6535\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6535\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc2a07fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiVIpUl662En"
      },
      "source": [
        "### 加入 Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh_SElzT62En",
        "outputId": "dcf5f7d4-f48a-45ff-a787-13e67540df6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4 = keras.Sequential(name='model-4')\n",
        "model_4.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
        "model_4.add(layers.Dropout(0.3))\n",
        "model_4.add(layers.Dense(64, activation='relu'))\n",
        "model_4.add(layers.Dropout(0.3))\n",
        "model_4.add(layers.Dense(1))\n",
        "\n",
        "model_4.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-4')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-4.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_4.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 8s - loss: 1.1799 - mean_absolute_error: 0.8582WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0819s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.5601 - mean_absolute_error: 0.4822 - val_loss: 1.1143 - val_mean_absolute_error: 0.6445\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6339 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6352 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6352 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6355 - val_loss: 1.1095 - val_mean_absolute_error: 0.6568\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6553\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1102 - val_mean_absolute_error: 0.6531\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6381 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1095 - val_mean_absolute_error: 0.6568\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6355 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6532\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6384 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc29fc9828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rSnob0H62Eq"
      },
      "source": [
        "### 驗證正則化的效能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGz8tUTu62Eq"
      },
      "source": [
        "Test model 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6dX65jr62Er",
        "outputId": "5d2a963c-5f0e-4bca-de7b-885a1c0b4f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = keras.models.load_model('/app/lab2-logs/models/Best-model-2.h5')\n",
        "y_pred = model_2.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_2: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_2: 42.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUPq1ao62Eu"
      },
      "source": [
        "Test model 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwQD-0bG62Eu",
        "outputId": "f06fb0f2-288e-4eef-e5fc-78fae7bf0d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3 = keras.models.load_model('/app/lab2-logs/models/Best-model-3.h5')\n",
        "y_pred = model_3.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_3: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_3: 42.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzog1SE62Ex"
      },
      "source": [
        "Test model 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2_BHbpJ62Ey",
        "outputId": "e2c67fee-b8d4-4c17-fbcf-7957f3b480cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4 = keras.models.load_model('/app/lab2-logs/models/Best-model-4.h5')\n",
        "y_pred = model_4.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_4: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_4: 42.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1gSHi2n62E1",
        "outputId": "823b42d5-8f6a-4e91-ef4e-bb078495c4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.225.38.180"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw1rLap1zu05"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}