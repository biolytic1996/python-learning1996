{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "1115 房價預測練習",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biolytic1996/python-learning1996/blob/master/1115_%E6%88%BF%E5%83%B9%E9%A0%90%E6%B8%AC%E7%B7%B4%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHKdD1qU62DF"
      },
      "source": [
        "# 實驗一：房價預測模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnhWEyv-62DH"
      },
      "source": [
        "### Import必要套件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abDmAO862DI"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRPHVV-D-FwS"
      },
      "source": [
        "## Step 1. 設定 Google Drive 連接 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjFZLoyA-I5K",
        "outputId": "0448f099-b2f0-4756-f96d-b2116005905c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # 點擊網址，選擇 Google 帳號登入，然後將授權碼貼回輸入框中"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja5FAB-HDGDb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFx5kPLa-YCL"
      },
      "source": [
        "!ln -fs /content/gdrive/My\\ Drive/ /app  #執行一次就可，否則會有錯誤訊息"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Rk_LcJDHNf",
        "outputId": "c8ef5e5f-da84-4ce9-d819-70da2e6bfaab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /app"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keDyMyFSb-r8"
      },
      "source": [
        "### https://www.kaggle.com/shivachandel/kc-house-data\n",
        "### http://www.stodolkiewicz.com/2020/01/28/tensorflow-2-regression-on-the-boston-housing-dataset-part-2-keras-callbacks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ujBpka1cE8"
      },
      "source": [
        "### 步驟 2. 下載 cuDNN 檔案\n",
        "\n",
        "1. 申請 Nvidia 帳號，申請網址為 http://bit.ly/2qfpOPj\n",
        "2. 下載 `cudnn-10.0-linux-x64-v7.5.0.56.tgz`，下載網址為 \n",
        "下載 cuDNN 檔案。下載網址為：http://bit.ly/2qfpOPj\n",
        "3. 將下載的檔案 `cudnn-10.0-linux-x64-v7.5.0.56.tgz` 放到 google drive 的 `Colab Notebooks/cuDNN/` 目錄下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1uWe9rV1i1p",
        "outputId": "090efdc7-539e-47e5-ca0f-20939a358198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tar -xzvf /app/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "\n",
        "# 檢查是否安裝成功\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda/include/cudnn.h\n",
            "cuda/NVIDIA_SLA_cuDNN_Support.txt\n",
            "cuda/lib64/libcudnn.so\n",
            "cuda/lib64/libcudnn.so.7\n",
            "cuda/lib64/libcudnn.so.7.5.0\n",
            "cuda/lib64/libcudnn_static.a\n",
            "#define CUDNN_MAJOR 7\n",
            "#define CUDNN_MINOR 5\n",
            "#define CUDNN_PATCHLEVEL 0\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "#include \"driver_types.h\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0i2MFvo62DN"
      },
      "source": [
        "### 數據讀取並分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OCiPHM2K62DN",
        "outputId": "b7c97e79-d50d-4d70-b441-8bc032c0f903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = pd.read_csv(\"/app/kc_house_data.csv\")\n",
        "# 顯示dataset的形狀，共21613比資料，每一比資料有21種不同資訊。\n",
        "data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21613, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3on7lew62DS",
        "outputId": "659d7dc5-f18d-4972-f320-30576be15eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# 將顯示列數設定為25，不然會有部份資料無法顯示\n",
        "pd.options.display.max_columns = 25\n",
        "# head 會顯示前五行的數據\n",
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
              "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
              "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
              "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
              "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
              "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
              "\n",
              "   sqft_lot  floors  waterfront  view  condition  grade  sqft_above  \\\n",
              "0      5650     1.0           0     0          3      7      1180.0   \n",
              "1      7242     2.0           0     0          3      7      2170.0   \n",
              "2     10000     1.0           0     0          3      6       770.0   \n",
              "3      5000     1.0           0     0          5      7      1050.0   \n",
              "4      8080     1.0           0     0          3      8      1680.0   \n",
              "\n",
              "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
              "0              0      1955             0    98178  47.5112 -122.257   \n",
              "1            400      1951          1991    98125  47.7210 -122.319   \n",
              "2              0      1933             0    98028  47.7379 -122.233   \n",
              "3            910      1965             0    98136  47.5208 -122.393   \n",
              "4              0      1987             0    98074  47.6168 -122.045   \n",
              "\n",
              "   sqft_living15  sqft_lot15  \n",
              "0           1340        5650  \n",
              "1           1690        7639  \n",
              "2           2720        8062  \n",
              "3           1360        5000  \n",
              "4           1800        7503  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZULEp-y62DW"
      },
      "source": [
        "各個數據的簡寫分別代表下面意思：\n",
        "- date：房屋出售日期。\n",
        "- price：房屋價格（目標）。\n",
        "- bedrooms：臥室數量。\n",
        "- bathrooms：浴室數量。\n",
        "- sqft_living：居住的坪數（平方英尺）。\n",
        "- sqft_lot：實際的坪數（平方英尺）。\n",
        "- floors：房屋總共樓層。\n",
        "- waterfront：海景房。\n",
        "- view：房屋是否看過。\n",
        "- condition：整體條件有多好。\n",
        "- grade：房屋的整體等級（根據King County評分系統）。\n",
        "- sqft_above：除了地下室外的坪數（平方英尺）。\n",
        "- sqft_basement：地下室的坪數（平方英尺）。\n",
        "- yr_built：房屋建造時間。\n",
        "- yr_renovated：何時重新裝修過（一些沒重新裝修過或是裝修紀錄沒被記錄到的數值都為0）。\n",
        "- zipcode：郵政編碼。\n",
        "- lat：緯度座標。\n",
        "- long：經度座標。\n",
        "- sqft_living15：2015年紀錄的居住坪數（可能是翻新的原因導致sqft_living15與sqft_living不同）。\n",
        "- sqft_lot15：2015年紀錄的實際坪數（可能是翻新的原因導致sqft_lot15與sqft_lot不同）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVWFc68N62DX"
      },
      "source": [
        "### 檢查資料的型態\n",
        "\n",
        "資料型態總共有五種：object(string),booleab, integer, float and categorical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21xrCehU62DY",
        "outputId": "cc843285-5e0e-4085-a1c2-fc8529585ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 int64\n",
              "date              object\n",
              "price            float64\n",
              "bedrooms           int64\n",
              "bathrooms        float64\n",
              "sqft_living        int64\n",
              "sqft_lot           int64\n",
              "floors           float64\n",
              "waterfront         int64\n",
              "view               int64\n",
              "condition          int64\n",
              "grade              int64\n",
              "sqft_above       float64\n",
              "sqft_basement      int64\n",
              "yr_built           int64\n",
              "yr_renovated       int64\n",
              "zipcode            int64\n",
              "lat              float64\n",
              "long             float64\n",
              "sqft_living15      int64\n",
              "sqft_lot15         int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIDSVGMoEBZh"
      },
      "source": [
        "date20141013T000000是物件  要處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90wPmfor62Dc"
      },
      "source": [
        "### 數據前處理\n",
        "轉換資料型態：\n",
        "因為數據集裡的date數據是字串（string）格式，而模型的輸入只接受數值格式，所以可以透過以下程式碼將其轉為數值，並分成年、月及日三種數據。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-KeJgIW62De",
        "outputId": "ac0cf988-dcc2-4b15-d908-cbd91d5247ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 將date日期拆為年、月和日並轉成數值\n",
        "data['year'] = pd.to_numeric(data['date'].str.slice(0, 4))#新增year欄位儲存 將原本的資料轉文字再切片擷取\n",
        "data['month'] = pd.to_numeric(data['date'].str.slice(4, 6))\n",
        "data['day'] = pd.to_numeric(data['date'].str.slice(6, 8))\n",
        "\n",
        "# 刪除沒有用的數據，inplace則是將更新後的資料存回原本的地方\n",
        "data.drop(['id'], axis=\"columns\", inplace=True)\n",
        "data.drop(['date'], axis=\"columns\", inplace=True)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "      <td>2014</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "      <td>2014</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "      <td>2014</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "      <td>2015</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
              "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
              "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
              "2  180000.0         2       1.00          770     10000     1.0           0   \n",
              "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
              "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
              "\n",
              "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
              "0     0          3      7      1180.0              0      1955             0   \n",
              "1     0          3      7      2170.0            400      1951          1991   \n",
              "2     0          3      6       770.0              0      1933             0   \n",
              "3     0          5      7      1050.0            910      1965             0   \n",
              "4     0          3      8      1680.0              0      1987             0   \n",
              "\n",
              "   zipcode      lat     long  sqft_living15  sqft_lot15  year  month  day  \n",
              "0    98178  47.5112 -122.257           1340        5650  2014     10   13  \n",
              "1    98125  47.7210 -122.319           1690        7639  2014     12    9  \n",
              "2    98028  47.7379 -122.233           2720        8062  2015      2   25  \n",
              "3    98136  47.5208 -122.393           1360        5000  2014     12    9  \n",
              "4    98074  47.6168 -122.045           1800        7503  2015      2   18  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ILOQaNA62Dj"
      },
      "source": [
        "分割數據集（Dataset）：將數據集切割成三個部份，訓練數據（Training data）、驗證數據（Validation data）和測試數據（Testing data）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij63xCTu62Dj"
      },
      "source": [
        "data_num = data.shape[0]\n",
        "# 取得一筆與data數量相同的亂數索引，主要目的是用於打散資料\n",
        "indexes = np.random.permutation(data_num)\n",
        "# 並將亂數索引值分為Train、validation和test分為，這裡的劃分比例為6:2:2\n",
        "train_indexes = indexes[:int(data_num *0.6)]\n",
        "val_indexes = indexes[int(data_num *0.6):int(data_num *0.8)]\n",
        "test_indexes = indexes[int(data_num *0.8):]\n",
        "# 透過索引值從data取出訓練資料、驗證資料和測試資料\n",
        "train_data = data.loc[train_indexes]\n",
        "val_data = data.loc[val_indexes]\n",
        "test_data = data.loc[test_indexes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OojnFm5-62Dn"
      },
      "source": [
        "### Normalization 正規化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RurfzID162Do"
      },
      "source": [
        "使用標準分數(Standard Score, 又稱z-score)將數據正規化，經過z-score正規化後數據的都會聚集在0附近， 標準差為1。 \n",
        "\n",
        "(x - 平均值) / 標準差"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qDtQMNKJ62Do"
      },
      "source": [
        "train_validation_data = pd.concat([train_data, val_data])\n",
        "mean = train_validation_data.mean()\n",
        "std = train_validation_data.std()\n",
        "\n",
        "train_data = (train_data - mean) / std\n",
        "val_data = (val_data - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mh9rTpB62Ds"
      },
      "source": [
        "### 建立Numpy array格式的訓練數據"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN5_H4Bh62Ds"
      },
      "source": [
        "x_train = np.array(train_data.drop('price', axis='columns'))\n",
        "y_train = np.array(train_data['price'])\n",
        "x_val = np.array(val_data.drop('price', axis='columns'))\n",
        "y_val = np.array(val_data['price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9z_JEa-62Dw"
      },
      "source": [
        "整理過後的資料共12967筆，且一筆資料有21種資訊(所以網路輸入必須為21)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWm5RX8262Dw",
        "outputId": "73c236da-b94d-4383-b3c8-680ec0b6e80d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12967, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZD7vqBv62D0"
      },
      "source": [
        "### 建立並訓練網路模型\n",
        "\n",
        "這裡建構三層全連接層的網路架構，並且使用ReLU作為隱藏層的激活函數，而由於需得到線性輸出，故輸出層不使用任何激活函數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syzeGcExh10L",
        "outputId": "4a42a274-a722-4c50-9cf1-67e1b4b6eb8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 建立一個Sequential型態的model\n",
        "model = keras.Sequential(name='model-1')\n",
        "# 第1層全連接層設為64個unit，將輸入形狀設定為(21, )，而實際上我們輸入的數據形狀為(batch_size, 21)\n",
        "model.add(layers.Dense(21, activation='relu', input_shape=(21,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# 最後一層全連接層設為1個unit\n",
        "model.add(layers.Dense(1))\n",
        "# 顯示網路模型架構\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model-1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_26 (Dense)             (None, 21)                462       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 64)                1408      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 6,095\n",
            "Trainable params: 6,095\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9ZhzEg62D5"
      },
      "source": [
        "設定訓練使用的優化器、損失函數和指標函數："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfrX2uEC62D5"
      },
      "source": [
        "model.compile(keras.optimizers.Adam(0.001),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.MeanAbsoluteError()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-585oEUi62D9"
      },
      "source": [
        "創建模型儲存目錄："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gxWwiYU62D9",
        "outputId": "d501b6d6-0216-426e-8fae-fcbe3b84c5e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_dir = '/app/lab2-logs/models/'\n",
        "%cd /app\n",
        "!rm -rf lab2-logs\n",
        "os.makedirs(model_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Tensorflow2/MMSLAB-TF2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw7U2Cc262EA"
      },
      "source": [
        "設定回調函數："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk7CcQ1y62EE"
      },
      "source": [
        "訓練網路模型："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t7XYNN6dCQQ",
        "outputId": "5458f833-8dea-4891-8a67-9d3d94be1894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# TensorBoard回調函數會幫忙紀錄訓練資訊，並存成TensorBoard的紀錄檔\n",
        "log_dir = os.path.join('/app/lab2-logs', 'model-1')\n",
        "# patience: number of epochs that produced the monitored quantity with no improvement after which training will be stopped.\n",
        "# Simply speaking - If there is no improvement in mse on the test set after any 15 epochs -> stop the training procedure\n",
        "monitor_val_acc = EarlyStopping(monitor = 'val_loss', patience=15)\n",
        "\n",
        "# save the best model ( = lowest mse) to a file 'best_model.hdf5'\n",
        "modelCheckpoint = ModelCheckpoint(model_dir + '/Best-model-1.h5', save_best_only = True)\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "# pass the above callbacks to callbacks parameter\n",
        "history = model.fit(x_train, y_train, \n",
        "                batch_size=64,  # 批次大小設為64\n",
        "                epochs=300,  # 整個dataset訓練300遍\n",
        "                validation_data=(x_val, y_val), \n",
        "                callbacks=[monitor_val_acc, modelCheckpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.5368 - mean_absolute_error: 0.4581 - val_loss: 1.1092 - val_mean_absolute_error: 0.6603\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9638 - mean_absolute_error: 0.6370 - val_loss: 1.1092 - val_mean_absolute_error: 0.6600\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6381 - val_loss: 1.1114 - val_mean_absolute_error: 0.6497\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6368 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9639 - mean_absolute_error: 0.6373 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9639 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1107 - val_mean_absolute_error: 0.6516\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6360 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9639 - mean_absolute_error: 0.6369 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6361 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6374 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6375 - val_loss: 1.1107 - val_mean_absolute_error: 0.6515\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6357 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6372 - val_loss: 1.1103 - val_mean_absolute_error: 0.6528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ_FMopPggbr"
      },
      "source": [
        "### 原課本程式 (執行階段發生錯誤)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU7m_eSA62EI"
      },
      "source": [
        "### 訓練結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5GsNEQw62EJ",
        "outputId": "eefee5de-a431-4b71-874d-72ede3b8e552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history.history.keys()  # 查看history儲存的資訊有哪些"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SVyhmqk62EN",
        "outputId": "2dd4e398-a713-4b80-f249-9a7dc67d6baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.ylim(0.02, 0.2)\n",
        "plt.title('Mean square error')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxAKwT0X62EQ",
        "outputId": "0e2f9b0d-ac55-4503-e674-6315fda7f23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['mean_absolute_error'], label='train')\n",
        "plt.plot(history.history['val_mean_absolute_error'], label='validation')\n",
        "plt.ylim(0.12, 0.26)\n",
        "plt.title('Mean absolute error')\n",
        "plt.ylabel('metrics')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAf/ElEQVR4nO3de7xUdb3/8ddbLiI3QcQbGwXNlIsIOKJleEkzsAItCU1TzOL3M03NevwOZY/wWJaPNDNPlGKZaRohidI53j2QeZRio4hcvCCibFDZYuAFb8Dn98damzPMXps94F7MAO/n4zEPZn2/37XmMwPMe9Zas76jiMDMzKzUTpUuwMzMqpMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzKIGmGpK+38DYvk/THltymWUtyQFhFSFoi6QNJu5e0PykpJPWqTGXVyWFileCAsEp6ETi9YUHSIUD7ypVjAJJal9O2uduwbY8DwirpVuCsouWzgVuKB0jaWdLVkl6W9Jqk6yXtkvZ1lfSfkuol/Su9X1O07gxJP5L0P5LekvRA6R5L0dhNbit1gKR/SnpT0t2SdkvXbSfpj5JWSlolaZakPdO+fSRNk/SGpEWSvtHE4x8rqa6kbYmkEyQNA74PjJb0tqSn0v5dJf1O0iuSlkn6saRWTWx/J0njJL2Q1jm5qP5e6V7buZJeBv5b0pj0dfuFpJXAZenj3ZK+Ri9J+oGkndJtNBqfVYdtWxwQVkkzgc6S+qRvbKcBpYdRrgQ+DgwEPgb0AH6Y9u0E/B7YD9gXeBf4Vcn6XwHOAfYA2gLfbaKWcrZ1FvA1YG9gLXBd2n42sCvQE+gG/N90fYBJQB2wD3Aq8BNJn26ihkwRcR/wE+DPEdExIg5Nu25O6/gYMAg4EWjqPMm3gJOBY9Ja/gVMKBlzDNAH+Gy6fASwGNgTuAL4j/R57p+OPYvktaWJ8batiwjffNvqN2AJcALwA+CnwDDgQaA1EEAvQMA7wAFF630CeLGJbQ4E/lW0PAP4QdHyN4H7yqwva1tXFi33BT4AWpGExmPAgJJt9ATWAZ2K2n4K3Jzevwz4Y3r/WKAu6zUqHZsu7wm8D+xS1HY6ML2J57MQOL5oeW/gw/T17pW+5vsX9Y8BXi5abpU+375Fbf8HmJE13rft4+bjhFZptwKPAL0pObwEdCc5JzFbUkObSN6skNQe+AVJuHRN+ztJahUR69LlV4u2twbomFVEmdtaWrTKS0AbYPf0OfQEJknqQrIXdCnJJ/U3IuKtkvUKma/E5tkvffxXil6bnUpqLB0/VdL6orZ1JEHToHTd4uXd08d7qajtJZI9uqbWt22cDzFZRUXESyQnq08C7izpfp3kUE2/iOiS3naNiIY3+e8ABwFHRERn4Oi0XWy+crbVs+j+viSfwF+PiA8j4t8joi/wSeDzJIdflgO7SepUst6yjMd/h6IT9Okht+5F/aXTLi8l2YPYvei16RwR/Zp4fkuB4UVju0REu4gorqX0MYqXX0+f736beC6eGno744CwanAu8OmIeKe4MSLWAzcCv5C0B4CkHpIajpF3IgmQVekJ1/EfoYZytnWmpL7p3sblwJSIWCfpOEmHpG/qb5K8ka6PiKUkh55+mp7IHpA+16yvqz4HtJP0OUltSA697VzU/xrQq+GkcES8AjwA/FxS5/Qk9AGSjmni+V0PXCFpPwBJ3SWNLPfFSfeiJqfb6JRu55ImnottJxwQVnER8UJE1DbR/W/AImCmpDeBh0g+6QNcC+xC8ul2JnDfRyijnG3dSnJi+FWgHXBh2r4XMIUkHBYCf0vHQnJeoBfJ3sRUYHxEPFS64YhYTXKO5Lckn8rfITm53eCO9M+Vkp5I759FcuJ9AclJ5ykk5xay/BKYBjwg6a30OR7RxNimfCutazHwKHA7cNNmbsO2IYrwXqGZmTXmPQgzM8uUa0BIGibp2fQCoXEZ/ZdIWiBprqSHG46Ppn37phc2LUzH9MqzVjMz21huh5jSE3bPAZ8hOZY6Czg9IhYUjTkO+EdErJF0HnBsRIxO+2YAV0TEg5I6kpz0W5NLsWZm1kieexBDgEURsTgiPiC5onSjb01ExPSiN/2ZQA2ApL5A64h4MB33tsPBzGzryvNCuR5sfOFMHZv+1sS5wL3p/Y+TfN3wTpILqB4CxhVdsASApLHAWIAOHTocdvDBB7dQ6WZmO4bZs2e/HhHds/qq4kpqSWeSXF3a8B3u1sBQkvllXgb+THIp/++K14uIicBEgEKhELW1TX1T0szMskh6qam+PA8xLWPjK09ryLiCVNIJJNMSjIiI99PmOmBOenhqLXAXMDjHWs3MrESeATELOFBSb0ltSWbqnFY8QNIg4AaScFhRsm4XSQ27PZ8muRjIzMy2ktwCIv3kfwFwP8nVpZMjYr6kyyWNSIddRTJ52h2S5kialq67jmRa5oclPU0yH86NedVqZmaNbTdXUvschNn25cMPP6Suro733nuv0qVsF9q1a0dNTQ1t2rTZqF3S7IjInGG4Kk5Sm5mVqquro1OnTvTq1YuiKc1tC0QEK1eupK6ujt69e5e9nqfaMLOq9N5779GtWzeHQwuQRLdu3TZ7b8wBYWZVy+HQcrbktXRAmJlZJgeEmVmGVatW8etf/3qz1zvppJNYtWpVDhVtfQ4IM7MMTQXE2rVrN7nePffcQ5cuXfIqa6vyt5jMzDKMGzeOF154gYEDB9KmTRvatWtH165deeaZZ3juuec4+eSTWbp0Ke+99x4XXXQRY8eOBaBXr17U1tby9ttvM3z4cD71qU/x2GOP0aNHD+6++2522WWXCj+z8jkgzKzq/ftf57Ng+Zstus2++3Rm/Bf6Ndl/5ZVXMm/ePObMmcOMGTP43Oc+x7x58zZ8TfSmm25it91249133+Xwww/nS1/6Et26ddtoG88//zx/+tOfuPHGG/nyl7/MX/7yF84888wWfR55ckCYmZVhyJAhG11DcN111zF16lQAli5dyvPPP98oIHr37s3AgQMBOOyww1iyZMlWq7clOCDMrOpt6pP+1tKhQ4cN92fMmMFDDz3E448/Tvv27Tn22GMzrzHYeeedN9xv1aoV77777laptaX4JLWZWYZOnTrx1ltvZfatXr2arl270r59e5555hlmzpy5lavbOrwHYWaWoVu3bhx11FH079+fXXbZhT333HND37Bhw7j++uvp06cPBx10EEceeWQFK82PJ+szs6q0cOFC+vTpU+kytitZr+mmJuvzISYzM8vkgDAzs0wOCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzsxbQsWNHAJYvX86pp56aOebYY4+lua/jX3vttaxZs2bDciWnD3dAmJm1oH322YcpU6Zs8fqlAVHJ6cMdEGZmGcaNG8eECRM2LF922WX8+Mc/5vjjj2fw4MEccsgh3H333Y3WW7JkCf379wfg3Xff5bTTTqNPnz6ccsopG83FdN5551EoFOjXrx/jx48HkgkAly9fznHHHcdxxx0HJNOHv/766wBcc8019O/fn/79+3PttddueLw+ffrwjW98g379+nHiiSe22JxPuU61IWkY8EugFfDbiLiypP8S4OvAWqAe+FpEvFTU3xlYANwVERfkWauZVbF7x8GrT7fsNvc6BIZf2WT36NGjufjiizn//PMBmDx5Mvfffz8XXnghnTt35vXXX+fII49kxIgRTf7e829+8xvat2/PwoULmTt3LoMHD97Qd8UVV7Dbbruxbt06jj/+eObOncuFF17INddcw/Tp09l999032tbs2bP5/e9/zz/+8Q8igiOOOIJjjjmGrl275jateG57EJJaAROA4UBf4HRJfUuGPQkUImIAMAX4WUn/j4BH8qrRzKwpgwYNYsWKFSxfvpynnnqKrl27stdee/H973+fAQMGcMIJJ7Bs2TJee+21JrfxyCOPbHijHjBgAAMGDNjQN3nyZAYPHsygQYOYP38+CxYs2GQ9jz76KKeccgodOnSgY8eOfPGLX+Tvf/87kN+04nnuQQwBFkXEYgBJk4CRJHsEAETE9KLxM4ENkSfpMGBP4D4gc54QM9tBbOKTfp5GjRrFlClTePXVVxk9ejS33XYb9fX1zJ49mzZt2tCrV6/Mab6b8+KLL3L11Vcza9YsunbtypgxY7ZoOw3ymlY8z3MQPYClRct1aVtTzgXuBZC0E/Bz4LubegBJYyXVSqqtr6//iOWamW1s9OjRTJo0iSlTpjBq1ChWr17NHnvsQZs2bZg+fTovvfTSJtc/+uijuf322wGYN28ec+fOBeDNN9+kQ4cO7Lrrrrz22mvce++9G9ZpaprxoUOHctddd7FmzRreeecdpk6dytChQ1vw2TZWFdN9SzqTZC/hmLTpm8A9EVHX1LE9gIiYCEyEZDbXvOs0sx1Lv379eOutt+jRowd77703Z5xxBl/4whc45JBDKBQKHHzwwZtc/7zzzuOcc86hT58+9OnTh8MOOwyAQw89lEGDBnHwwQfTs2dPjjrqqA3rjB07lmHDhrHPPvswffr/HmQZPHgwY8aMYciQIQB8/etfZ9CgQbn+Sl1u031L+gRwWUR8Nl3+HkBE/LRk3AnAfwDHRMSKtO02YCiwHugItAV+HRHjmno8T/dttn3xdN8tb3On+85zD2IWcKCk3sAy4DTgKyWFDQJuAIY1hANARJxRNGYMyYnsJsPBzMxaXm7nICJiLXABcD+wEJgcEfMlXS5pRDrsKpI9hDskzZE0La96zMxs8+R6DiIi7gHuKWn7YdH9E8rYxs3AzS1dm5lVv4ho8hoD2zxbcjrBV1KbWVVq164dK1eu3KI3NttYRLBy5UratWu3WetVxbeYzMxK1dTUUFdXh7/C3jLatWtHTU3NZq3jgDCzqtSmTRt69+5d6TJ2aD7EZGZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmXINCEnDJD0raZGkcRn9l0haIGmupIcl7Ze2D5T0uKT5ad/oPOs0M7PGcgsISa2ACcBwoC9wuqS+JcOeBAoRMQCYAvwsbV8DnBUR/YBhwLWSuuRVq5mZNZbnHsQQYFFELI6ID4BJwMjiARExPSLWpIszgZq0/bmIeD69vxxYAXTPsVYzMyuRZ0D0AJYWLdelbU05F7i3tFHSEKAt8EJG31hJtZJq6+vrP2K5ZmZWrCpOUks6EygAV5W07w3cCpwTEetL14uIiRFRiIhC9+7ewTAza0mtc9z2MqBn0XJN2rYRSScAlwLHRMT7Re2dgf8CLo2ImTnWaWZmGfLcg5gFHCipt6S2wGnAtOIBkgYBNwAjImJFUXtbYCpwS0RMybFGMzNrQm4BERFrgQuA+4GFwOSImC/pckkj0mFXAR2BOyTNkdQQIF8GjgbGpO1zJA3Mq1YzM2tMEVHpGlpEoVCI2traSpdhZrZNkTQ7IgpZfVVxktrMzKqPA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMjkgzMwskwPCzMwyOSDMzCyTA8LMzDI5IMzMLJMDwszMMuUaEJKGSXpW0iJJ4zL6L5G0QNJcSQ9L2q+o72xJz6e3s/Os08zMGsstICS1AiYAw4G+wOmS+pYMexIoRMQAYArws3Td3YDxwBHAEGC8pK551WpmZo3luQcxBFgUEYsj4gNgEjCyeEBETI+INeniTKAmvf9Z4MGIeCMi/gU8CAzLsVYzMyuRZ0D0AJYWLdelbU05F7h3C9c1M7MWVlZASLpIUmclfifpCUkntlQRks4ECsBVm7neWEm1kmrr6+tbqhwzM6P8PYivRcSbwIlAV+CrwJXNrLMM6Fm0XJO2bUTSCcClwIiIeH9z1o2IiRFRiIhC9+7dy3wqZmZWjnIDQumfJwG3RsT8oramzAIOlNRbUlvgNGDaRhuVBgE3kITDiqKu+4ETJXVNT06fmLaZmdlW0rrMcbMlPQD0Br4nqROwflMrRMRaSReQvLG3Am6KiPmSLgdqI2IaySGljsAdkgBejogREfGGpB+RhAzA5RHxxmY/OzMz22KKiOYHSTsBA4HFEbFKUjegR0TMzbvAchUKhaitra10GWZm2xRJsyOikNVX7iGmkcALEbEqXV4H7N8SxZmZWXUqNyDGR8TqhoU0KMbnU5KZmVWDcgMia1y55y/MzGwbVG5A1Eq6RtIB6e0aYHaehZmZWWWVGxDfAj4A/pze3gfOz6soMzOrvLIOE0XEO0Cj2VjNzGz7tcmAkHRtRFws6a9Ao+/DRsSI3CozM7OKam4P4tb0z6vzLsTMzKrLJgMiImanv+swNiLO2Eo1mZlZFWj2JHVErAP2S+dTMjOzHUS51zIsBv5H0jTgnYbGiLgml6rMzKziyg2IF9LbTkCntK35SZzMzGybVW5ALIiIO4obJI3KoR4zM6sS5V4o970y28zMbDvR3HUQw0l+JKiHpOuKujoDa/MszMzMKqu5Q0zLgVpgBBvPvfQW8O28ijIzs8pr7jqIp4CnJN2ejt03Ip7dKpWZmVlFlXsOYhgwB7gPQNLA9CuvZma2nSo3IC4DhgCrACJiDsnvU5uZ2Xaq3ID4sPgX5VK+DsLMbDtW7nUQ8yV9BWgl6UDgQuCx/MoyM7NK25wfDOpH8kNBtwOrgYvyKsrMzCqv3IDom95aA+2AkcCs5laSNEzSs5IWSWr0g0OSjpb0hKS1kk4t6fuZpPmSFkq6TpLKrNXMzFpAuYeYbgO+C8wD1pezQjpN+ATgM0AdMEvStIhYUDTsZWBMuu3idT8JHAUMSJseBY4BZpRZr5mZfUTlBkR9RPx1M7c9BFgUEYsBJE0i2fPYEBARsSTtKw2dINlTaQsIaAO8tpmPb2ZmH0G5ATFe0m+Bh0nOQwAQEXduYp0ewNKi5TrgiHIeLCIelzQdeIUkIH4VEQvLrNXMzFpAuQFxDnAwySf5hk/7AWwqILaYpI8BfYCatOlBSUMj4u8l48YCYwH23XffPEoxM9thlRsQh0fEQZu57WVAz6LlmrStHKcAMyPibQBJ9wKfADYKiIiYCEwEKBQKvi7DzKwFlfstpsck9d3Mbc8CDpTUO/250tOAcqfneBk4RlJrSW1ITlD7EJOZ2VZUbkAcCcxJv7I6V9LTkuZuaoWIWAtcANxP8uY+OSLmS7pc0ggASYdLqgNGATdImp+uPoXkF+yeBp4CntqCk+RmZvYRKKL5IzOS9stqj4iXWryiLVQoFKK2trbSZZiZbVMkzY6IQlZfWecgqikIzMxs6yj3EJOZme1gHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFmZpkcEGZmlinXgJA0TNKzkhZJGpfRf7SkJyStlXRqSd++kh6QtFDSAkm98qzVzMw2lltASGoFTACGA32B0yX1LRn2MjAGuD1jE7cAV0VEH2AIsCKvWs3MrLHWOW57CLAoIhYDSJoEjAQWNAyIiCVp3/riFdMgaR0RD6bj3s6xTjMzy5DnIaYewNKi5bq0rRwfB1ZJulPSk5KuSvdINiJprKRaSbX19fUtULKZmTWo1pPUrYGhwHeBw4H9SQ5FbSQiJkZEISIK3bt337oVmplt5/IMiGVAz6LlmrStHHXAnIhYHBFrgbuAwS1cn5mZbUKeATELOFBSb0ltgdOAaZuxbhdJDbsFn6bo3IWZmeUvt4BIP/lfANwPLAQmR8R8SZdLGgEg6XBJdcAo4AZJ89N115EcXnpY0tOAgBvzqtXMzBpTRFS6hhZRKBSitra20mWYmW1TJM2OiEJWX7WepDYzswpzQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZplwDQtIwSc9KWiRpXEb/0ZKekLRW0qkZ/Z0l1Un6VZ51mplZY7kFhKRWwARgONAXOF1S35JhLwNjgNub2MyPgEfyqtHMzJqW5x7EEGBRRCyOiA+AScDI4gERsSQi5gLrS1eWdBiwJ/BAjjWamVkT8gyIHsDSouW6tK1ZknYCfg58t5lxYyXVSqqtr6/f4kLNzKyxaj1J/U3gnoio29SgiJgYEYWIKHTv3n0rlWZmtmNoneO2lwE9i5Zr0rZyfAIYKumbQEegraS3I6LRiW4zM8tHngExCzhQUm+SYDgN+Eo5K0bEGQ33JY0BCg4HM7OtK7dDTBGxFrgAuB9YCEyOiPmSLpc0AkDS4ZLqgFHADZLm51WPmZltHkVEpWtoEYVCIWpraytdhpnZNkXS7IgoZPVV60lqMzOrMAeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWXKNSAkDZP0rKRFksZl9B8t6QlJayWdWtQ+UNLjkuZLmitpdJ51mplZY7kFhKRWwARgONAXOF1S35JhLwNjgNtL2tcAZ0VEP2AYcK2kLnnVamZmjbXOcdtDgEURsRhA0iRgJLCgYUBELEn71hevGBHPFd1fLmkF0B1YlWO9ZmZWJM+A6AEsLVquA47Y3I1IGgK0BV7I6BsLjE0X35b07BbU2WB34PWPsH7eqr0+qP4aq70+cI0todrrg+qqcb+mOvIMiI9M0t7ArcDZEbG+tD8iJgITW+ixaiOi0BLbykO11wfVX2O11weusSVUe32wbdQI+Z6kXgb0LFquSdvKIqkz8F/ApRExs4VrMzOzZuQZELOAAyX1ltQWOA2YVs6K6fipwC0RMSXHGs3MrAm5BURErAUuAO4HFgKTI2K+pMsljQCQdLikOmAUcIOk+enqXwaOBsZImpPeBuZVa6pFDlXlqNrrg+qvsdrrA9fYEqq9Ptg2akQRUekazMysCvlKajMzy+SAMDOzTDt8QDQ3HUilSeopabqkBenUIxdVuqYsklpJelLSf1a6liySukiaIukZSQslfaLSNRWT9O3073eepD9JalcFNd0kaYWkeUVtu0l6UNLz6Z9dq7DGq9K/57mSplZ6FoasGov6viMpJO1eidqas0MHRJnTgVTaWuA7EdEXOBI4vwprBLiI5MsI1eqXwH0RcTBwKFVUq6QewIVAISL6A61IvvVXaTeTTHVTbBzwcEQcCDycLlfSzTSu8UGgf0QMAJ4Dvre1iypxM41rRFJP4ESSKYeq0g4dEBRNBxIRHwAN04FUjYh4JSKeSO+/RfLG1qOyVW1MUg3wOeC3la4li6RdSb4V9zuAiPggIqpt2pbWwC6SWgPtgeUVroeIeAR4o6R5JPCH9P4fgJO3alElsmqMiAfSb1ECzCS5BqtimngdAX4B/D+gar8ptKMHRNZ0IFX15ltMUi9gEPCPylbSyLUk/9AbXe1eJXoD9cDv08Ngv5XUodJFNYiIZcDVJJ8kXwFWR8QDla2qSXtGxCvp/VeBPStZTBm+Btxb6SJKSRoJLIuIpypdy6bs6AGxzZDUEfgLcHFEvFnpehpI+jywIiJmV7qWTWgNDAZ+ExGDgHeo/KGRDdLj+CNJgmwfoIOkMytbVfMi+Y581X76lXQpySHa2ypdSzFJ7YHvAz+sdC3N2dED4iNNB7K1SGpDEg63RcSdla6nxFHACElLSA7RfVrSHytbUiN1QF1ENOx5TSEJjGpxAvBiRNRHxIfAncAnK1xTU15L50hrmCttRYXrySRpDPB54Iyovou9DiD5MPBU+v+mBnhC0l4VrSrDjh4QWzwdyNYiSSTHzhdGxDWVrqdURHwvImoiohfJ6/ffEVFVn34j4lVgqaSD0qbjKZp2vgq8DBwpqX369308VXQSvcQ04Oz0/tnA3RWsJZOkYSSHPEdExJpK11MqIp6OiD0iolf6/6YOGJz+O60qO3RANDUdSGWrauQo4Kskn8wbph05qdJFbYO+BdwmaS4wEPhJhevZIN2zmQI8ATxN8v+y4lMxSPoT8DhwkKQ6SecCVwKfkfQ8yZ7PlVVY46+ATsCD6f+X66uwxm2Cp9owM7NMO/QehJmZNc0BYWZmmRwQZmaWyQFhZmaZHBBmZpbJAWFWQZKOrdYZcM0cEGZmlskBYVYGSWdK+md64dUN6e9fvC3pF+nvODwsqXs6dqCkmUW/R9A1bf+YpIckPSXpCUkHpJvvWPRbFbelV1Mj6cr0d0DmSrq6Qk/ddmAOCLNmSOoDjAaOioiBwDrgDKADUBsR/YC/AePTVW4B/i39PYKni9pvAyZExKEkcy01zIo6CLiY5DdJ9geOktQNOAXol27nx/k+S7PGHBBmzTseOAyYJWlOurw/yfTmf07H/BH4VPrbE10i4m9p+x+AoyV1AnpExFSAiHivaJ6gf0ZEXUSsB+YAvYDVwHvA7yR9Eai6OYVs++eAMGuegD9ExMD0dlBEXJYxbkvnrXm/6P46oHU6T9gQkjmaPg/ct4XbNttiDgiz5j0MnCppD9jwu8z7kfz/OTUd8xXg0YhYDfxL0tC0/avA39JfA6yTdHK6jZ3T3wXIlP7+x64RcQ/wbZKfSTXbqlpXugCzahcRCyT9AHhA0k7Ah8D5JD88NCTtW0FyngKSabCvTwNgMXBO2v5V4AZJl6fbGLWJh+0E3C2pHckezCUt/LTMmuXZXM22kKS3I6Jjpeswy4sPMZmZWSbvQZiZWSbvQZiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVmm/w8lRU1kaekF3wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwq6o12e62ET"
      },
      "source": [
        "測試數據的誤差百分比：用測試數據預測房屋價格並與答案計算誤差百分比。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pXrckh262EU",
        "outputId": "8debf242-3472-4e24-e22b-96dfaf927ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 載入模型\n",
        "model = keras.models.load_model('/app/lab2-logs/models/Best-model-1.h5')\n",
        "# 先將房屋價格取出\n",
        "y_test = np.array(test_data['price'])\n",
        "# 標準化數據\n",
        "test_data = (test_data - mean) / std\n",
        "# 將輸入數據存成Numpy 格式\n",
        "x_test = np.array(test_data.drop('price', axis='columns'))\n",
        "# 預測測試數據\n",
        "y_pred = model.predict(x_test)\n",
        "# 將預測結果轉換回來(因為訓練時的訓練目標也有經過標準化)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "# 計算平均的誤差百分比\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "# 顯示誤差百分比\n",
        "print(\"Model_1 Percentage Error: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_1 Percentage Error: 43.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDdS4gu262EW"
      },
      "source": [
        "### TensorBoard 可視化工具"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id9FClNy62EX"
      },
      "source": [
        "# 這行指令可以幫助我們直接在jupyter notebook上顯示TensorBoard\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a6jznxns62Ec"
      },
      "source": [
        "%tensorboard --port 9530 --logdir /app/lab2-logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_xlBTzE62Ef"
      },
      "source": [
        "# 實驗二：過擬合問題\n",
        "\n",
        "### 方法一、減少網路權重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "exnLSm5662Ef",
        "outputId": "4a1fcc9f-9a0e-43ab-c728-7566209f65f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = keras.Sequential(name='model-2')\n",
        "model_2.add(layers.Dense(16, activation='relu', input_shape=(21,)))\n",
        "model_2.add(layers.Dense(16, activation='relu'))\n",
        "model_2.add(layers.Dense(1))\n",
        "\n",
        "model_2.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-2')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-2.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_2.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 27s - loss: 2.4924 - mean_absolute_error: 0.8881WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.2651s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.9318 - mean_absolute_error: 0.6234 - val_loss: 1.1104 - val_mean_absolute_error: 0.6527\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6351 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6384 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1102 - val_mean_absolute_error: 0.6531\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1094 - val_mean_absolute_error: 0.6574\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6386 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6348 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6383 - val_loss: 1.1096 - val_mean_absolute_error: 0.6559\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6381 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6348 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1103 - val_mean_absolute_error: 0.6531\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1102 - val_mean_absolute_error: 0.6532\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6352 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1094 - val_mean_absolute_error: 0.6574\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6386 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6374 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1103 - val_mean_absolute_error: 0.6528\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6355 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6381 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6553\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6384 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6386 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6382 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6351 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6352 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6559\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6385 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6387 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1103 - val_mean_absolute_error: 0.6531\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6381 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6544\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1103 - val_mean_absolute_error: 0.6529\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc2a1bbac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9bGkqub62Ej"
      },
      "source": [
        "### 加入L1或L2 正則化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "11OLybIw62Ej",
        "outputId": "c4cf6b2a-8b81-4d7f-aa81-e1a2be82a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3 = keras.Sequential(name='model-3')\n",
        "model_3.add(layers.Dense(64, \n",
        "                         kernel_regularizer=keras.regularizers.l2(0.001), \n",
        "                         activation='relu', input_shape=(21,)))\n",
        "model_3.add(layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'))\n",
        "model_3.add(layers.Dense(1))\n",
        "\n",
        "model_3.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-3')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-3.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_3.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 10s - loss: 1.1976 - mean_absolute_error: 0.7815WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0975s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6248 - val_loss: nan - val_mean_absolute_error: 0.6572\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6592\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6523\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6511\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6516\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6588\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6603\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6395 - val_loss: nan - val_mean_absolute_error: 0.6509\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6346 - val_loss: nan - val_mean_absolute_error: 0.6579\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6566\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6358 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6575\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6382 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6358 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6574\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6387 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6382 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6351 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6571\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6374 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6352 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6351 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6566\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6568\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6383 - val_loss: nan - val_mean_absolute_error: 0.6538\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6361 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6563\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6532\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6531\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6531\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6542\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6532\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6533\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6355 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6386 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6353 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6383 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6379 - val_loss: nan - val_mean_absolute_error: 0.6534\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6373 - val_loss: nan - val_mean_absolute_error: 0.6537\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6536\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6371 - val_loss: nan - val_mean_absolute_error: 0.6543\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6548\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6352 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6377 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6552\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6560\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6378 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6381 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6360 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6356 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6550\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6544\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6567\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6391 - val_loss: nan - val_mean_absolute_error: 0.6540\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6535\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6547\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6370 - val_loss: nan - val_mean_absolute_error: 0.6549\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6368 - val_loss: nan - val_mean_absolute_error: 0.6559\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6364 - val_loss: nan - val_mean_absolute_error: 0.6558\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6365 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6561\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6385 - val_loss: nan - val_mean_absolute_error: 0.6541\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6359 - val_loss: nan - val_mean_absolute_error: 0.6557\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6363 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6539\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6535\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6357 - val_loss: nan - val_mean_absolute_error: 0.6545\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6551\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6366 - val_loss: nan - val_mean_absolute_error: 0.6562\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6564\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6554\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6372 - val_loss: nan - val_mean_absolute_error: 0.6553\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6367 - val_loss: nan - val_mean_absolute_error: 0.6546\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6556\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6375 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6565\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6376 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6369 - val_loss: nan - val_mean_absolute_error: 0.6555\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: nan - mean_absolute_error: 0.6362 - val_loss: nan - val_mean_absolute_error: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc2a07fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiVIpUl662En"
      },
      "source": [
        "### 加入 Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh_SElzT62En",
        "outputId": "dcf5f7d4-f48a-45ff-a787-13e67540df6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4 = keras.Sequential(name='model-4')\n",
        "model_4.add(layers.Dense(64, activation='relu', input_shape=(21,)))\n",
        "model_4.add(layers.Dropout(0.3))\n",
        "model_4.add(layers.Dense(64, activation='relu'))\n",
        "model_4.add(layers.Dropout(0.3))\n",
        "model_4.add(layers.Dense(1))\n",
        "\n",
        "model_4.compile(keras.optimizers.Adam(0.001),\n",
        "                loss=keras.losses.MeanSquaredError(),\n",
        "                metrics=[keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "log_dir = os.path.join('lab2-logs', 'model-4')\n",
        "model_cbk = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "model_mckp = keras.callbacks.ModelCheckpoint(model_dir + '/Best-model-4.h5', \n",
        "                                             monitor='val_mean_absolute_error', \n",
        "                                             save_best_only=True, \n",
        "                                             mode='min')\n",
        "model_4.fit(x_train, y_train, \n",
        "            batch_size=64 ,\n",
        "            epochs=300, \n",
        "            validation_data=(x_val, y_val), \n",
        "            callbacks=[model_cbk, model_mckp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  2/203 [..............................] - ETA: 8s - loss: 1.1799 - mean_absolute_error: 0.8582WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0819s). Check your callbacks.\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.5601 - mean_absolute_error: 0.4822 - val_loss: 1.1143 - val_mean_absolute_error: 0.6445\n",
            "Epoch 2/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9637 - mean_absolute_error: 0.6339 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 3/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 4/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6352 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 5/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 6/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 7/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 8/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 9/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 10/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 11/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 12/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 13/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 14/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 15/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 16/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 17/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 18/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 19/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 20/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 21/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 22/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 23/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 24/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 25/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 26/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 27/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 28/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 29/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 30/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6352 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 31/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 32/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 33/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 34/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6355 - val_loss: 1.1095 - val_mean_absolute_error: 0.6568\n",
            "Epoch 35/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 36/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 37/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 38/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 39/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 40/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 41/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 42/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 43/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 44/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 45/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 46/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 47/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 48/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 49/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1095 - val_mean_absolute_error: 0.6567\n",
            "Epoch 50/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 51/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 52/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 53/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 54/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 55/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 56/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 57/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 58/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 59/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 60/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 61/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 62/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 63/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 64/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 65/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 66/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 67/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 68/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 69/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 70/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 71/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 72/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 73/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 74/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 75/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 76/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 77/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 78/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 79/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 80/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 81/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 82/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 83/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 84/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 85/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 86/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 87/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 88/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 89/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 90/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 91/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 92/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 93/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 94/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 95/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 96/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 97/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 98/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 99/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 100/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 101/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 102/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 103/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 104/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 105/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 106/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 107/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 108/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 109/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 110/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 111/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 112/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 113/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6540\n",
            "Epoch 114/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6535\n",
            "Epoch 115/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 116/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1103 - val_mean_absolute_error: 0.6530\n",
            "Epoch 117/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 118/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 119/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 120/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 121/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 122/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6371 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 123/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 124/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 125/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 126/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 127/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 128/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 129/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 130/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 131/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 132/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6353 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 133/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 134/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9636 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6534\n",
            "Epoch 135/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 136/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6553\n",
            "Epoch 137/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 138/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 139/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 140/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 141/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 142/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 143/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 144/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 145/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 146/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 147/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 148/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 149/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 150/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 151/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 152/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 153/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 154/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 155/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 156/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 157/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 158/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 159/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 160/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 161/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 162/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 163/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 164/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 165/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 166/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 167/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 168/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 169/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 170/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 171/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 172/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 173/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 174/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 175/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 176/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1096 - val_mean_absolute_error: 0.6562\n",
            "Epoch 177/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 178/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 179/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 180/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 181/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 182/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 183/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 184/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 185/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1096 - val_mean_absolute_error: 0.6561\n",
            "Epoch 186/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 187/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 188/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 189/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 190/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 191/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 192/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 193/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 194/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 195/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6358 - val_loss: 1.1096 - val_mean_absolute_error: 0.6564\n",
            "Epoch 196/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 197/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6382 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 198/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6359 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 199/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1097 - val_mean_absolute_error: 0.6556\n",
            "Epoch 200/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 201/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1102 - val_mean_absolute_error: 0.6531\n",
            "Epoch 202/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 203/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 204/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 205/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 206/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 207/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 208/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1102 - val_mean_absolute_error: 0.6533\n",
            "Epoch 209/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 210/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 211/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1101 - val_mean_absolute_error: 0.6536\n",
            "Epoch 212/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 213/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 214/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 215/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 216/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 217/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6376 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 218/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 219/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 220/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 221/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6358 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 222/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6377 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 223/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 224/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6381 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 225/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 226/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 227/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1100 - val_mean_absolute_error: 0.6543\n",
            "Epoch 228/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 229/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 230/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 231/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 232/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 233/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 234/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 235/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6366 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 236/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6369 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 237/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1095 - val_mean_absolute_error: 0.6566\n",
            "Epoch 238/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6377 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 239/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 240/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 241/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6364 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 242/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6376 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n",
            "Epoch 243/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6373 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 244/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 245/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6539\n",
            "Epoch 246/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 247/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6548\n",
            "Epoch 248/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6554\n",
            "Epoch 249/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 250/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6545\n",
            "Epoch 251/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 252/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6372 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 253/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6369 - val_loss: 1.1100 - val_mean_absolute_error: 0.6541\n",
            "Epoch 254/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6357 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 255/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6378 - val_loss: 1.1101 - val_mean_absolute_error: 0.6538\n",
            "Epoch 256/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 257/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6375 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 258/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6380 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 259/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6361 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 260/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6374 - val_loss: 1.1102 - val_mean_absolute_error: 0.6535\n",
            "Epoch 261/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1099 - val_mean_absolute_error: 0.6544\n",
            "Epoch 262/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 263/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6363 - val_loss: 1.1099 - val_mean_absolute_error: 0.6548\n",
            "Epoch 264/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 265/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 266/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 267/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6354 - val_loss: 1.1095 - val_mean_absolute_error: 0.6568\n",
            "Epoch 268/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6383 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 269/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 270/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 271/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6374 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 272/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1101 - val_mean_absolute_error: 0.6539\n",
            "Epoch 273/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 274/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6553\n",
            "Epoch 275/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 276/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6370 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 277/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6363 - val_loss: 1.1098 - val_mean_absolute_error: 0.6552\n",
            "Epoch 278/300\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.9635 - mean_absolute_error: 0.6368 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 279/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6375 - val_loss: 1.1101 - val_mean_absolute_error: 0.6537\n",
            "Epoch 280/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6365 - val_loss: 1.1100 - val_mean_absolute_error: 0.6542\n",
            "Epoch 281/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6355 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 282/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6378 - val_loss: 1.1097 - val_mean_absolute_error: 0.6559\n",
            "Epoch 283/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 284/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1102 - val_mean_absolute_error: 0.6532\n",
            "Epoch 285/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6360 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 286/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6371 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 287/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6372 - val_loss: 1.1098 - val_mean_absolute_error: 0.6551\n",
            "Epoch 288/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6362 - val_loss: 1.1097 - val_mean_absolute_error: 0.6557\n",
            "Epoch 289/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6370 - val_loss: 1.1099 - val_mean_absolute_error: 0.6546\n",
            "Epoch 290/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6368 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 291/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6364 - val_loss: 1.1096 - val_mean_absolute_error: 0.6563\n",
            "Epoch 292/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6365 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 293/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6380 - val_loss: 1.1097 - val_mean_absolute_error: 0.6558\n",
            "Epoch 294/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6359 - val_loss: 1.1096 - val_mean_absolute_error: 0.6560\n",
            "Epoch 295/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6379 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 296/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6356 - val_loss: 1.1096 - val_mean_absolute_error: 0.6565\n",
            "Epoch 297/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9635 - mean_absolute_error: 0.6384 - val_loss: 1.1099 - val_mean_absolute_error: 0.6547\n",
            "Epoch 298/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6367 - val_loss: 1.1098 - val_mean_absolute_error: 0.6549\n",
            "Epoch 299/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6366 - val_loss: 1.1098 - val_mean_absolute_error: 0.6550\n",
            "Epoch 300/300\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9634 - mean_absolute_error: 0.6361 - val_loss: 1.1097 - val_mean_absolute_error: 0.6555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc29fc9828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rSnob0H62Eq"
      },
      "source": [
        "### 驗證正則化的效能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGz8tUTu62Eq"
      },
      "source": [
        "Test model 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6dX65jr62Er",
        "outputId": "5d2a963c-5f0e-4bca-de7b-885a1c0b4f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = keras.models.load_model('/app/lab2-logs/models/Best-model-2.h5')\n",
        "y_pred = model_2.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_2: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_2: 42.86%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUPq1ao62Eu"
      },
      "source": [
        "Test model 3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwQD-0bG62Eu",
        "outputId": "f06fb0f2-288e-4eef-e5fc-78fae7bf0d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3 = keras.models.load_model('/app/lab2-logs/models/Best-model-3.h5')\n",
        "y_pred = model_3.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_3: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_3: 42.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzog1SE62Ex"
      },
      "source": [
        "Test model 4:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2_BHbpJ62Ey",
        "outputId": "e2c67fee-b8d4-4c17-fbcf-7957f3b480cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4 = keras.models.load_model('/app/lab2-logs/models/Best-model-4.h5')\n",
        "y_pred = model_4.predict(x_test)\n",
        "y_pred = np.reshape(y_pred * std['price'] + mean['price'], y_test.shape)\n",
        "percentage_error = np.mean(np.abs(y_test - y_pred)) / np.mean(y_test) * 100\n",
        "print(\"Model_4: {:.2f}%\".format(percentage_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_4: 42.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1gSHi2n62E1",
        "outputId": "823b42d5-8f6a-4e91-ef4e-bb078495c4eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl ipecho.net/plain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.225.38.180"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw1rLap1zu05"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}